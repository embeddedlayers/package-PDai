% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chat.R
\name{chat.openAI}
\alias{chat.openAI}
\title{OpenAI Chat API Interaction Function}
\usage{
chat.openAI(
  apiKey,
  payload,
  temperature = 1,
  top_p = 1,
  model = "gpt-3.5-turbo",
  chatID = NULL
)
}
\arguments{
\item{apiKey}{A character string specifying the API key for OpenAI.}

\item{payload}{A list of message objects formatted according to the OpenAI API requirements.}

\item{temperature}{Numeric, controls randomness in the response generation, where higher values result in more random responses.}

\item{top_p}{Numeric, controls diversity of the response generation by limiting the likelihood of the alternatives considered by the model.}

\item{model}{Character string, specifies the OpenAI model to use for generating responses, default is "gpt-3.5-turbo".}

\item{chatID}{Optional character string, an identifier for the chat session, can be used to link responses with their queries.}
}
\value{
A list containing two elements: \code{results}, which includes the API response, and \code{chatID}, the session identifier if provided.
If the request fails, returns a character string describing the error with the HTTP status code.
}
\description{
This function interacts with the OpenAI Chat API by sending a payload of messages and receiving responses.
It allows for the customization of the interaction through parameters such as temperature and top_p,
and uses the specified API key for authentication.
}
\examples{
\dontrun{
  apiKey <- "your_openai_api_key_here"
  messages <- list(list("role" = "user", "content" = "Hello, world!"))
  response <- chat.openAI(apiKey = apiKey, payload = messages)
  print(response)
}
}
